{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Classification_MNIST_DNN_TensorFlow.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SatyaThakur/MNIST_Classification_DNN_Tensorflow/blob/master/Classification_MNIST_DNN_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxZ5-X7IFT9M",
        "colab_type": "text"
      },
      "source": [
        "# MNIST Classification with DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "274AGjfRa6Uy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "86ea1ba6-f23d-4be2-bc19-80ba3c42606f"
      },
      "source": [
        "pip install tensorflow==1.14.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 100kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.29.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (47.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKqz2BsxFT9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "b08f2714-88b9-4cf0-fef3-237023710f4d"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suI6vY7BFT9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reset tensorflow graph\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDNBC1CpFT9V",
        "colab_type": "text"
      },
      "source": [
        "Step 1 : Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD89yKlXFT9W",
        "colab_type": "code",
        "outputId": "c33546d6-30d5-4880-c609-ab619bbaa316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnists = input_data.read_data_sets('MNIST_data')\n",
        "trai = mnists.train.images\n",
        "trt = mnists.train.labels\n",
        "trt[0:1]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-cea1a206c578>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDEdpa7QFT9a",
        "colab_type": "code",
        "outputId": "69abe133-7c9e-4077-c21a-b2dc47fcb02c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AvYLaKoFT9e",
        "colab_type": "code",
        "outputId": "dd6d9b32-0d4a-4a81-a25b-f379a5126cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "mnist"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f36eb159400>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f36eb1596a0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f36eb159710>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXg9yPyUFT9h",
        "colab_type": "text"
      },
      "source": [
        "Step 1a : Get Training and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "354LDl3JFT9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = mnist.train.images\n",
        "trainY = mnist.train.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aLZm5CAFT9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testX = mnist.test.images\n",
        "testY = mnist.test.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfX4sd8IFT9n",
        "colab_type": "text"
      },
      "source": [
        "How many Training and Test Examples?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XkjUyNEFT9o",
        "colab_type": "code",
        "outputId": "b2c2c72a-758f-453e-ca97-672eeafe06cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainY[0:1]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK6A3dg0FT9t",
        "colab_type": "text"
      },
      "source": [
        "Lets define some parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p3Wg7tBFT9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logs_path = \"C:/Users/saten/Documents/Satendra/AI and ML/Deep Learning/Tensorflow Basics\"\n",
        "learning_rate = 0.04\n",
        "n_features = trainX.shape[1]\n",
        "n_classes = trainY.shape[1]\n",
        "model_name = 'mnist.ckpt'\n",
        "\n",
        "#How many examples to feed for training at one time\n",
        "batch_size = 100\n",
        "\n",
        "#How many times all the data to be shown\n",
        "training_epochs = 100\n",
        "\n",
        "K = 200\n",
        "L = 100\n",
        "M = 60\n",
        "N = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR2DhWLQFT9x",
        "colab_type": "text"
      },
      "source": [
        "# Build the Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ES5VqzFT9x",
        "colab_type": "text"
      },
      "source": [
        "Input placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHTjPCDSFT9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('input'):\n",
        "    # None -> batch size can be any size, with n_features\n",
        "    x = tf.placeholder(tf.float32, shape=[None, n_features], name=\"x-input\") \n",
        "    # target n_classes output classes\n",
        "    y_ = tf.placeholder(tf.float32, shape=[None, n_classes], name=\"y-input\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-E000WcFT92",
        "colab_type": "text"
      },
      "source": [
        "Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5_flRv_FT92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('layer_1'):\n",
        "    W1 = tf.Variable(tf.truncated_normal([n_features, K], stddev=0.1))\n",
        "    b1 = tf.Variable(tf.zeros([K]))\n",
        "    Y1 = tf.nn.sigmoid(tf.add(tf.matmul(x,W1),b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pX2pvI3FT95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('layer_2'):\n",
        "    W2 = tf.Variable(tf.truncated_normal([K, L], stddev=0.1))\n",
        "    b2 = tf.Variable(tf.zeros([L]))\n",
        "    Y2 = tf.nn.sigmoid(tf.add(tf.matmul(Y1,W2),b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh-EYs3WFT99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('layer_3'):\n",
        "    W3 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
        "    b3 = tf.Variable(tf.zeros([M]))\n",
        "    Y3 = tf.nn.sigmoid(tf.add(tf.matmul(Y2,W3),b3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUCbAnPlFT9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('layer_4'):\n",
        "    W4 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\n",
        "    b4 = tf.Variable(tf.zeros([N]))\n",
        "    Y4 = tf.nn.sigmoid(tf.add(tf.matmul(Y3,W4),b4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "opW375ElFT-C",
        "colab_type": "text"
      },
      "source": [
        "Prediction    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9fpS8EqFT-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"Output\"):\n",
        "    W5 = tf.Variable(tf.truncated_normal([N,n_classes], stddev=0.1))\n",
        "    b5 = tf.Variable(tf.zeros([n_classes]))\n",
        "    y = tf.nn.softmax(tf.matmul(Y4,W5) + b5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBzwa0JsFT-G",
        "colab_type": "text"
      },
      "source": [
        "Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4GsnEXUFT-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('Loss'):\n",
        "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4bjKvN6FT-J",
        "colab_type": "text"
      },
      "source": [
        "GradientDescent Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErKQF2lRFT-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('train'):        \n",
        "    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTAve7f-FT-M",
        "colab_type": "text"
      },
      "source": [
        "Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M4IYPA6FT-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope('Accuracy'):\n",
        "    prediction = tf.argmax(y,1,name=\"Predict\")    \n",
        "    correct_prediction = tf.equal(prediction, tf.argmax(y_,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRunThssFT-P",
        "colab_type": "text"
      },
      "source": [
        "Loss and Accuracy Logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGk8CYFRFT-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a summary for our cost and accuracy\n",
        "training_loss = tf.summary.scalar(\"training_loss\", cross_entropy)\n",
        "training_accuracy = tf.summary.scalar(\"training_accuracy\", accuracy)\n",
        "test_loss = tf.summary.scalar(\"test_loss\", cross_entropy)\n",
        "test_accuracy = tf.summary.scalar(\"test_accuracy\", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz7QK8bRFT-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a Saver to save the graph\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_2b1pb-FT-V",
        "colab_type": "text"
      },
      "source": [
        "# Execute the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb722I7yFT-V",
        "colab_type": "code",
        "outputId": "1c3a7ba7-745c-4046-a028-e6e29c20154f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "#Start Graph execution\n",
        "with tf.Session() as sess:\n",
        "    # variables need to be initialized before we can use them\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # create log writer object\n",
        "    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
        "\n",
        "    # perform training cycles\n",
        "    for epoch in range(training_epochs):\n",
        "        \n",
        "        # number of batches in one epoch\n",
        "        batch_count = int(trainX.shape[0]/batch_size)\n",
        "        \n",
        "        for i in range(batch_count):\n",
        "            batch_x  = trainX[i*batch_size:i*batch_size+batch_size]\n",
        "            batch_y  = trainY[i*batch_size:i*batch_size+batch_size]\n",
        "\n",
        "            # perform the operations we defined earlier on batch\n",
        "            _,acc,loss = sess.run([train_op, training_accuracy,training_loss], \n",
        "                                  feed_dict={x: batch_x, y_: batch_y})\n",
        "            \n",
        "            #log training accuracy and loss\n",
        "            writer.add_summary(acc, epoch * batch_count + i)\n",
        "            writer.add_summary(loss, epoch * batch_count + i)    \n",
        "                       \n",
        "        #Test loss and accuracy\n",
        "        #pls note we are giving test data\n",
        "        acc,loss = sess.run([test_accuracy,test_loss],\n",
        "                                   feed_dict={x: testX, y_: testY})\n",
        "        writer.add_summary(acc, epoch * batch_count + i)\n",
        "        writer.add_summary(loss, epoch * batch_count + i)\n",
        "        \n",
        "        if epoch % 5 == 0: \n",
        "            print (\"Epoch: \", epoch)\n",
        "            print (\"Test Accuracy: \", accuracy.eval(feed_dict={x: testX, y_: testY}))               \n",
        "    \n",
        "    \n",
        "    #Save the model\n",
        "    saver.save(sess, logs_path + '/' + model_name)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Test Accuracy:  0.1028\n",
            "Epoch:  5\n",
            "Test Accuracy:  0.1028\n",
            "Epoch:  10\n",
            "Test Accuracy:  0.1028\n",
            "Epoch:  15\n",
            "Test Accuracy:  0.1028\n",
            "Epoch:  20\n",
            "Test Accuracy:  0.2784\n",
            "Epoch:  25\n",
            "Test Accuracy:  0.4244\n",
            "Epoch:  30\n",
            "Test Accuracy:  0.6769\n",
            "Epoch:  35\n",
            "Test Accuracy:  0.7977\n",
            "Epoch:  40\n",
            "Test Accuracy:  0.8503\n",
            "Epoch:  45\n",
            "Test Accuracy:  0.8821\n",
            "Epoch:  50\n",
            "Test Accuracy:  0.9043\n",
            "Epoch:  55\n",
            "Test Accuracy:  0.9171\n",
            "Epoch:  60\n",
            "Test Accuracy:  0.9257\n",
            "Epoch:  65\n",
            "Test Accuracy:  0.9329\n",
            "Epoch:  70\n",
            "Test Accuracy:  0.9382\n",
            "Epoch:  75\n",
            "Test Accuracy:  0.9422\n",
            "Epoch:  80\n",
            "Test Accuracy:  0.9453\n",
            "Epoch:  85\n",
            "Test Accuracy:  0.9475\n",
            "Epoch:  90\n",
            "Test Accuracy:  0.9501\n",
            "Epoch:  95\n",
            "Test Accuracy:  0.952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwiNF1LpFT-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}